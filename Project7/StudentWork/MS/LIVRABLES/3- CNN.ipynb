{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/miljanstojiljkovic/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/Users/miljanstojiljkovic/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "\n",
    "from matplotlib.pyplot import imshow\n",
    "from keras.preprocessing import image\n",
    "from keras import applications\n",
    "from keras.models import Sequential\n",
    "import os,sys\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import decomposition\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/Y/1-OpenClassroom - Data Scientist/09- Projet 7/Projet/database\n"
     ]
    }
   ],
   "source": [
    "cd database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_array(fname):\n",
    "    return np.load(open(fname,'rb'))\n",
    "def load_Cropped_data():\n",
    "    X_train=load_array('train_dataset.npy')\n",
    "    train_labels=load_array('train_labels.npy')\n",
    "    X_test=load_array('test_dataset.npy','rb')\n",
    "    test_labels=load_array('test_labels.npy')\n",
    "    return X_train,train_labels,X_test,test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_target=load_array('train_labels.npy')\n",
    "valid_target=load_array('valid_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_tensor=load_array('train_dataset.npy')\n",
    "valid_tensor=load_array('valid_dataset.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_target=load_array('test_labels.npy')\n",
    "test_tensor=load_array('test_dataset.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Normalize_Input(X):\n",
    "    minimum=0\n",
    "    maximum=255\n",
    "    X-minimum/(maximum-minimum)\n",
    "    return X                \n",
    "\n",
    "# pre-process the data for Keras\n",
    "train_tensor=Normalize_Input(train_tensor)\n",
    "valid_tensor=Normalize_Input(valid_tensor)\n",
    "test_tensor=Normalize_Input(test_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# create and configure augmented image generator\n",
    "datagen = ImageDataGenerator(\n",
    "    width_shift_range=0.1,  # randomly shift images horizontally (20% of total width)\n",
    "    height_shift_range=0.1,  # randomly shift images vertically (20% of total height)\n",
    "    horizontal_flip=True    # randomly flip images horizontally\n",
    "    ) \n",
    "\n",
    "# fit augmented image generator on data\n",
    "datagen.fit(train_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_1 (Batch (None, 224, 224, 3)       12        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 222, 222, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 111, 111, 16)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 111, 111, 16)      64        \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 109, 109, 32)      4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 54, 54, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 54, 54, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 52, 52, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 26, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 26, 26, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 24, 24, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 10, 10, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 5, 5, 256)         1024      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 120)               30840     \n",
      "=================================================================\n",
      "Total params: 425,444\n",
      "Trainable params: 424,446\n",
      "Non-trainable params: 998\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(BatchNormalization(input_shape=(224, 224, 3)))\n",
    "model.add(Conv2D(filters=16, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(filters=256, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "model.add(Dense(120, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "480/480 [==============================] - 933s 2s/step - loss: 4.4641 - acc: 0.0398 - val_loss: 4.2452 - val_acc: 0.0479\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4.24522, saving model to saved_models/weights.bestaugmented.from_scratch.hdf5\n",
      "Epoch 2/10\n",
      "480/480 [==============================] - 928s 2s/step - loss: 4.1419 - acc: 0.0718 - val_loss: 3.8423 - val_acc: 0.1050\n",
      "\n",
      "Epoch 00002: val_loss improved from 4.24522 to 3.84230, saving model to saved_models/weights.bestaugmented.from_scratch.hdf5\n",
      "Epoch 3/10\n",
      "480/480 [==============================] - 911s 2s/step - loss: 3.9127 - acc: 0.0972 - val_loss: 3.9676 - val_acc: 0.0933\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 3.84230\n",
      "Epoch 4/10\n",
      "480/480 [==============================] - 911s 2s/step - loss: 3.7025 - acc: 0.1260 - val_loss: 3.5859 - val_acc: 0.1467\n",
      "\n",
      "Epoch 00004: val_loss improved from 3.84230 to 3.58587, saving model to saved_models/weights.bestaugmented.from_scratch.hdf5\n",
      "Epoch 5/10\n",
      "480/480 [==============================] - 909s 2s/step - loss: 3.5441 - acc: 0.1528 - val_loss: 3.7280 - val_acc: 0.1392\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 3.58587\n",
      "Epoch 6/10\n",
      "480/480 [==============================] - 909s 2s/step - loss: 3.3790 - acc: 0.1793 - val_loss: 3.3262 - val_acc: 0.1967\n",
      "\n",
      "Epoch 00006: val_loss improved from 3.58587 to 3.32622, saving model to saved_models/weights.bestaugmented.from_scratch.hdf5\n",
      "Epoch 7/10\n",
      "480/480 [==============================] - 903s 2s/step - loss: 3.2384 - acc: 0.2038 - val_loss: 3.2562 - val_acc: 0.2079\n",
      "\n",
      "Epoch 00007: val_loss improved from 3.32622 to 3.25619, saving model to saved_models/weights.bestaugmented.from_scratch.hdf5\n",
      "Epoch 8/10\n",
      "480/480 [==============================] - 915s 2s/step - loss: 3.1069 - acc: 0.2285 - val_loss: 3.0946 - val_acc: 0.2429\n",
      "\n",
      "Epoch 00008: val_loss improved from 3.25619 to 3.09464, saving model to saved_models/weights.bestaugmented.from_scratch.hdf5\n",
      "Epoch 9/10\n",
      "480/480 [==============================] - 902s 2s/step - loss: 2.9938 - acc: 0.2503 - val_loss: 3.0153 - val_acc: 0.2433\n",
      "\n",
      "Epoch 00009: val_loss improved from 3.09464 to 3.01532, saving model to saved_models/weights.bestaugmented.from_scratch.hdf5\n",
      "Epoch 10/10\n",
      "480/480 [==============================] - 910s 2s/step - loss: 2.8872 - acc: 0.2747 - val_loss: 2.9646 - val_acc: 0.2671\n",
      "\n",
      "Epoch 00010: val_loss improved from 3.01532 to 2.96456, saving model to saved_models/weights.bestaugmented.from_scratch.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xcdbe10438>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 20\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.bestaugmented.from_scratch.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "### Using Image Augmentation\n",
    "model.fit_generator(datagen.flow(train_tensor, train_target, batch_size=batch_size),\n",
    "                    validation_data=(valid_tensor, valid_target), \n",
    "                    steps_per_epoch=train_tensor.shape[0] // batch_size,\n",
    "                    epochs=epochs, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('saved_models/weights.bestaugmented.from_scratch.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8580/8580 [==============================] - 324s 38ms/step\n"
     ]
    }
   ],
   "source": [
    "rounded_predictions_1 = model.predict_classes(test_tensor, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "test_accuracy = 100*accuracy_score(test_target, rounded_predictions_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.783216783216783"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model a bit further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "batch_size = 20\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.bestaugmented.from_scratch.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "### Using Image Augmentation\n",
    "model.fit_generator(datagen.flow(train_tensor, train_target, batch_size=batch_size),\n",
    "                    validation_data=(valid_tensor, valid_target), \n",
    "                    steps_per_epoch=train_tensor.shape[0] // batch_size,\n",
    "                    epochs=epochs, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get index of predicted dog breed for each image in test set\n",
    "dog_breed_predictions = [np.argmax(model.predict(np.expand_dims(tensor, axis=0))) for tensor in test_tensor]\n",
    "\n",
    "# report test accuracy\n",
    "test_accuracy = 100*np.sum(np.array(dog_breed_predictions)==np.argmax(test_target, axis=1))/len(dog_breed_predictions)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using a pre-trained model : VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications import vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg16_model = vgg16.VGG16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg16_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.engine.training.Model"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(vgg16_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "for layer in vgg16_model.layers[:-1]:\n",
    "    model2.add(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "=================================================================\n",
      "Total params: 134,260,544\n",
      "Trainable params: 134,260,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in model2.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model2.add(Dense(120, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 120)               491640    \n",
      "=================================================================\n",
      "Total params: 134,752,184\n",
      "Trainable params: 491,640\n",
      "Non-trainable params: 134,260,544\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model2.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "480/480 [==============================] - 6075s 13s/step - loss: 4.2840 - acc: 0.2944 - val_loss: 3.2234 - val_acc: 0.4679\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.22343, saving model to saved_models/vgg16.hdf5\n",
      "Epoch 2/5\n",
      "480/480 [==============================] - 6052s 13s/step - loss: 3.2943 - acc: 0.4252 - val_loss: 3.0442 - val_acc: 0.5308\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.22343 to 3.04420, saving model to saved_models/vgg16.hdf5\n",
      "Epoch 3/5\n",
      "480/480 [==============================] - 6112s 13s/step - loss: 3.0207 - acc: 0.4796 - val_loss: 3.6145 - val_acc: 0.4950\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 3.04420\n",
      "Epoch 4/5\n",
      "480/480 [==============================] - 6015s 13s/step - loss: 2.7806 - acc: 0.5154 - val_loss: 3.3424 - val_acc: 0.5113\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 3.04420\n",
      "Epoch 5/5\n",
      "480/480 [==============================] - 6014s 13s/step - loss: 2.6740 - acc: 0.5452 - val_loss: 3.3253 - val_acc: 0.5438\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 3.04420\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xcde1a7b70>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 5\n",
    "batch_size = 20\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/vgg16.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "### Using Image Augmentation\n",
    "model2.fit_generator(datagen.flow(train_tensor, train_target, batch_size=batch_size),\n",
    "                    validation_data=(valid_tensor, valid_target), \n",
    "                    steps_per_epoch=train_tensor.shape[0] // batch_size,\n",
    "                    epochs=epochs, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features = model2.predict(test_tensor, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.3352244e-01, 1.4821845e-25, 2.6143494e-23, ..., 2.6557844e-05,\n",
       "        3.8210635e-14, 6.1165532e-15],\n",
       "       [9.9900526e-01, 3.4960309e-17, 4.0417505e-14, ..., 1.0777613e-05,\n",
       "        1.1858420e-14, 5.9058078e-23],\n",
       "       [5.6016414e-11, 2.1315002e-21, 4.2321167e-26, ..., 1.1751288e-15,\n",
       "        5.9199679e-18, 8.0077579e-30],\n",
       "       ...,\n",
       "       [2.1061902e-13, 3.1585683e-15, 2.7211703e-25, ..., 8.2788797e-11,\n",
       "        3.2087601e-12, 9.9999905e-01],\n",
       "       [5.4075491e-28, 9.9920532e-29, 2.4880652e-35, ..., 8.3040828e-13,\n",
       "        1.1137285e-05, 3.6553797e-04],\n",
       "       [2.8982959e-19, 2.5560879e-27, 2.1546240e-30, ..., 3.7542244e-11,\n",
       "        1.6713378e-07, 9.9999988e-01]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog_breed_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8580/8580 [==============================] - 4328s 504ms/step\n"
     ]
    }
   ],
   "source": [
    "rounded_predictions = model2.predict_classes(test_tensor, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "test_accuracy_2 = 100*accuracy_score(test_target, rounded_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51.96969696969697"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using a pre-trained model : MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.6/mobilenet_1_0_224_tf.h5\n",
      "17227776/17225924 [==============================] - 46s 3us/step\n"
     ]
    }
   ],
   "source": [
    "mobile = keras.applications.mobilenet.MobileNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)    (None, 225, 225, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 112, 112, 32)      864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (ReLU)            (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 32)      288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (ReLU)        (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 112, 112, 64)      2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (ReLU)        (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, 113, 113, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (ReLU)        (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 56, 56, 128)       8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 56, 56, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, 57, 57, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (ReLU)        (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 28, 28, 256)       32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 28, 28, 256)       65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, 29, 29, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (ReLU)        (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 14, 14, 512)       131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, 15, 15, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 7, 7, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 7, 7, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (ReLU)       (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 7, 7, 1024)        524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 7, 7, 1024)        9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 7, 7, 1024)        1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_preds (Conv2D)          (None, 1, 1, 1000)        1025000   \n",
      "_________________________________________________________________\n",
      "act_softmax (Activation)     (None, 1, 1, 1000)        0         \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 1000)              0         \n",
      "=================================================================\n",
      "Total params: 4,253,864\n",
      "Trainable params: 4,231,976\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mobile.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.engine.training.Model"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mobile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mobile_tune = Sequential()\n",
    "for layer in mobile.layers:\n",
    "    mobile_tune.add(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mobile_tune.add(Dense(120, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in mobile_tune.layers[:-5]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1_pad (ZeroPadding2D)    (None, 225, 225, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 112, 112, 32)      864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (ReLU)            (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 32)      288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (ReLU)        (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 112, 112, 64)      2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (ReLU)        (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, 113, 113, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (ReLU)        (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 56, 56, 128)       8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 56, 56, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, 57, 57, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (ReLU)        (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 28, 28, 256)       32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 28, 28, 256)       65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, 29, 29, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (ReLU)        (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 14, 14, 512)       131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, 15, 15, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 7, 7, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 7, 7, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (ReLU)       (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 7, 7, 1024)        524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 7, 7, 1024)        9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 7, 7, 1024)        1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_preds (Conv2D)          (None, 1, 1, 1000)        1025000   \n",
      "_________________________________________________________________\n",
      "act_softmax (Activation)     (None, 1, 1, 1000)        0         \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 120)               120120    \n",
      "=================================================================\n",
      "Total params: 4,373,984\n",
      "Trainable params: 1,145,120\n",
      "Non-trainable params: 3,228,864\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mobile_tune.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mobile_tune.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "480/480 [==============================] - 1541s 3s/step - loss: 4.6419 - acc: 0.1623 - val_loss: 4.7838 - val_acc: 0.0100\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4.78380, saving model to saved_models/mobile.hdf5\n",
      "Epoch 2/5\n",
      "480/480 [==============================] - 1474s 3s/step - loss: 4.3702 - acc: 0.1997 - val_loss: 4.7726 - val_acc: 0.0092\n",
      "\n",
      "Epoch 00002: val_loss improved from 4.78380 to 4.77258, saving model to saved_models/mobile.hdf5\n",
      "Epoch 3/5\n",
      "480/480 [==============================] - 1527s 3s/step - loss: 4.1410 - acc: 0.1870 - val_loss: 4.7746 - val_acc: 0.0133\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 4.77258\n",
      "Epoch 4/5\n",
      " 42/480 [=>............................] - ETA: 16:25 - loss: 4.0267 - acc: 0.1750"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-78605922422f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                     epochs=epochs, callbacks=[checkpointer], verbose=1)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "batch_size = 20\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/mobile.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "### Using Image Augmentation\n",
    "mobile_tune.fit_generator(datagen.flow(train_tensor, train_target, batch_size=batch_size),\n",
    "                    validation_data=(valid_tensor, valid_target), \n",
    "                    steps_per_epoch=train_tensor.shape[0] // batch_size,\n",
    "                    epochs=epochs, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy isn't satisfying, so we won't continue the training. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test for only feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg16_model = VGG16(weights='imagenet', include_top=True)\n",
    "vgg16_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "for layer in vgg16_model.layers[:-3]:\n",
    "    model.add(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 5210s 543ms/step\n"
     ]
    }
   ],
   "source": [
    "vgg16_train_feature = model.predict(train_tensor, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400/2400 [==============================] - 1296s 540ms/step\n"
     ]
    }
   ],
   "source": [
    "vgg16_valid_feature = model.predict(valid_tensor, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9600, 25088)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg16_train_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_and_test_model(classifier, Xtrain, ytrain, Xtest, ytest, is_neural_net=False):\n",
    "    print(\"=\"*80)\n",
    "    print('Training ', classifier)\n",
    "    classifier.fit(Xtrain, ytrain)\n",
    "\n",
    "    pred = classifier.predict(Xtrain)\n",
    "    score = metrics.accuracy_score(ytrain, pred)\n",
    "\n",
    "##    print 'Accuracy on training set = ', score*100\n",
    "\n",
    "    pred = classifier.predict(Xtest)\n",
    "    score = metrics.accuracy_score(ytest, pred)\n",
    "\n",
    "    print('Accuracy on test set = ', score*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Training  DummyClassifier(constant=None, random_state=None, strategy='stratified')\n",
      "Accuracy on test set =  0.6666666666666667\n",
      "================================================================================\n",
      "Training  SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False)\n",
      "Accuracy on test set =  46.58333333333333\n",
      "================================================================================\n",
      "Training  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Accuracy on test set =  56.875\n",
      "================================================================================\n",
      "Training  MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "Accuracy on test set =  41.25\n",
      "================================================================================\n",
      "Training  Perceptron(alpha=0.0001, class_weight=None, eta0=1.0, fit_intercept=True,\n",
      "      max_iter=None, n_iter=None, n_jobs=1, penalty=None, random_state=0,\n",
      "      shuffle=True, tol=None, verbose=0, warm_start=False)\n",
      "Accuracy on test set =  46.0\n",
      "================================================================================\n",
      "Training  PassiveAggressiveClassifier(C=1.0, average=False, class_weight=None,\n",
      "              fit_intercept=True, loss='hinge', max_iter=None, n_iter=None,\n",
      "              n_jobs=1, random_state=None, shuffle=True, tol=None,\n",
      "              verbose=0, warm_start=False)\n",
      "Accuracy on test set =  56.333333333333336\n",
      "================================================================================\n",
      "Training  RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "Accuracy on test set =  10.083333333333332\n",
      "================================================================================\n",
      "Training  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False)\n",
      "Accuracy on test set =  1.0416666666666665\n"
     ]
    }
   ],
   "source": [
    "dummy = DummyClassifier()\n",
    "sgd = SGDClassifier()\n",
    "lr = LogisticRegression()\n",
    "mn = MultinomialNB()\n",
    "perceptron = Perceptron()\n",
    "pac = PassiveAggressiveClassifier()\n",
    "rfc = RandomForestClassifier()\n",
    "mlpc = MLPClassifier()\n",
    "\n",
    "for classifier in [dummy, sgd, lr, mn, perceptron, pac, rfc, mlpc]:\n",
    "    train_and_test_model(classifier, vgg16_train_feature, train_target, vgg16_valid_feature, valid_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mobile Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mobile = keras.applications.mobilenet.MobileNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)    (None, 225, 225, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 112, 112, 32)      864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (ReLU)            (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 32)      288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (ReLU)        (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 112, 112, 64)      2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (ReLU)        (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, 113, 113, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (ReLU)        (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 56, 56, 128)       8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 56, 56, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, 57, 57, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (ReLU)        (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 28, 28, 256)       32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 28, 28, 256)       65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, 29, 29, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (ReLU)        (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 14, 14, 512)       131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, 15, 15, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 7, 7, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 7, 7, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (ReLU)       (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 7, 7, 1024)        524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 7, 7, 1024)        9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 7, 7, 1024)        1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_preds (Conv2D)          (None, 1, 1, 1000)        1025000   \n",
      "_________________________________________________________________\n",
      "act_softmax (Activation)     (None, 1, 1, 1000)        0         \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 1000)              0         \n",
      "=================================================================\n",
      "Total params: 4,253,864\n",
      "Trainable params: 4,231,976\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mobile.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mobile_tune = Sequential()\n",
    "for layer in mobile.layers:\n",
    "    mobile_tune.add(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 1848s 193ms/step\n"
     ]
    }
   ],
   "source": [
    "mobile_train_feature = mobile_tune.predict(train_tensor, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400/2400 [==============================] - 431s 180ms/step\n"
     ]
    }
   ],
   "source": [
    "mobile_valid_feature = mobile_tune.predict(valid_tensor, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Training  DummyClassifier(constant=None, random_state=None, strategy='stratified')\n",
      "Accuracy on test set =  0.5\n",
      "================================================================================\n",
      "Training  SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False)\n",
      "Accuracy on test set =  0.8333333333333334\n",
      "================================================================================\n",
      "Training  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Accuracy on test set =  1.9166666666666665\n",
      "================================================================================\n",
      "Training  MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "Accuracy on test set =  2.125\n",
      "================================================================================\n",
      "Training  SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Accuracy on test set =  1.25\n",
      "================================================================================\n",
      "Training  Perceptron(alpha=0.0001, class_weight=None, eta0=1.0, fit_intercept=True,\n",
      "      max_iter=None, n_iter=None, n_jobs=1, penalty=None, random_state=0,\n",
      "      shuffle=True, tol=None, verbose=0, warm_start=False)\n",
      "Accuracy on test set =  0.9583333333333333\n",
      "================================================================================\n",
      "Training  PassiveAggressiveClassifier(C=1.0, average=False, class_weight=None,\n",
      "              fit_intercept=True, loss='hinge', max_iter=None, n_iter=None,\n",
      "              n_jobs=1, random_state=None, shuffle=True, tol=None,\n",
      "              verbose=0, warm_start=False)\n",
      "Accuracy on test set =  1.0833333333333335\n",
      "================================================================================\n",
      "Training  RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "Accuracy on test set =  2.625\n",
      "================================================================================\n",
      "Training  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False)\n",
      "Accuracy on test set =  4.833333333333333\n"
     ]
    }
   ],
   "source": [
    "for classifier in [dummy, sgd, lr, mn, svc, perceptron, pac, rfc, mlpc]:\n",
    "    train_and_test_model(classifier, mobile_train_feature, train_target, mobile_valid_feature, valid_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.vgg19 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = preprocess_input(train_tensor)\n",
    "x_valid = preprocess_input(valid_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_model = VGG19(weights='imagenet')\n",
    "model_vgg19 = Model(inputs=base_model.input, outputs=base_model.get_layer('flatten').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 6824s 711ms/step\n",
      "2400/2400 [==============================] - 1724s 718ms/step\n"
     ]
    }
   ],
   "source": [
    "vgg19_train_features = model_vgg19.predict(x_train, verbose = 1)\n",
    "vgg19_valid_features = model_vgg19.predict(x_valid, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('vgg19_features.pickle', 'wb') as f:\n",
    "    pickle.dump([vgg19_train_features, vgg19_valid_features], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2400, 25088)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg19_valid_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Training  DummyClassifier(constant=None, random_state=None, strategy='stratified')\n",
      "Accuracy on test set =  1.1666666666666667\n",
      "================================================================================\n",
      "Training  SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False)\n",
      "Accuracy on test set =  65.58333333333334\n",
      "================================================================================\n",
      "Training  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Accuracy on test set =  72.58333333333333\n",
      "================================================================================\n",
      "Training  MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "Accuracy on test set =  63.083333333333336\n",
      "================================================================================\n",
      "Training  Perceptron(alpha=0.0001, class_weight=None, eta0=1.0, fit_intercept=True,\n",
      "      max_iter=None, n_iter=None, n_jobs=1, penalty=None, random_state=0,\n",
      "      shuffle=True, tol=None, verbose=0, warm_start=False)\n",
      "Accuracy on test set =  65.125\n",
      "================================================================================\n",
      "Training  PassiveAggressiveClassifier(C=1.0, average=False, class_weight=None,\n",
      "              fit_intercept=True, loss='hinge', max_iter=None, n_iter=None,\n",
      "              n_jobs=1, random_state=None, shuffle=True, tol=None,\n",
      "              verbose=0, warm_start=False)\n",
      "Accuracy on test set =  72.54166666666667\n",
      "================================================================================\n",
      "Training  RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "Accuracy on test set =  21.5\n",
      "================================================================================\n",
      "Training  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False)\n",
      "Accuracy on test set =  28.999999999999996\n"
     ]
    }
   ],
   "source": [
    "for classifier in [dummy, sgd, lr, mn, perceptron, pac, rfc, mlpc]:\n",
    "    train_and_test_model(classifier, vgg19_train_features, train_target, vgg19_valid_features, valid_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87916544/87910968 [==============================] - 447s 5us/step\n"
     ]
    }
   ],
   "source": [
    "# create the base pre-trained model\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "# and a logistic layer -- let's say we have 200 classes\n",
    "predictions = Dense(120, activation='softmax')(x)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# this is the model we will train\n",
    "inception = Model(inputs=base_model.input, outputs=predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "160/160 [==============================] - 2172s 14s/step - loss: 2.6189 - acc: 0.3989 - val_loss: 15.7720 - val_acc: 0.0096\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 15.77200, saving model to saved_models/inception.hdf5\n",
      "Epoch 2/5\n",
      "160/160 [==============================] - 2131s 13s/step - loss: 1.4944 - acc: 0.5821 - val_loss: 15.8217 - val_acc: 0.0108\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 15.77200\n",
      "Epoch 3/5\n",
      "160/160 [==============================] - 2133s 13s/step - loss: 1.2771 - acc: 0.6405 - val_loss: 15.9433 - val_acc: 0.0079\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 15.77200\n",
      "Epoch 4/5\n",
      "160/160 [==============================] - 2143s 13s/step - loss: 1.1240 - acc: 0.6760 - val_loss: 15.9227 - val_acc: 0.0063\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 15.77200\n",
      "Epoch 5/5\n",
      "160/160 [==============================] - 2137s 13s/step - loss: 1.0581 - acc: 0.6934 - val_loss: 15.9589 - val_acc: 0.0042\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 15.77200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xd84662d30>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inception.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "epochs = 5\n",
    "batch_size = 60\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/inception.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "### Using Image Augmentation\n",
    "inception.fit_generator(datagen.flow(train_tensor, train_target, batch_size=batch_size),\n",
    "                    validation_data=(valid_tensor, valid_target), \n",
    "                    steps_per_epoch=train_tensor.shape[0] // batch_size,\n",
    "                    epochs=epochs, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_7\n",
      "1 conv2d_1\n",
      "2 batch_normalization_1\n",
      "3 activation_1\n",
      "4 conv2d_2\n",
      "5 batch_normalization_2\n",
      "6 activation_2\n",
      "7 conv2d_3\n",
      "8 batch_normalization_3\n",
      "9 activation_3\n",
      "10 max_pooling2d_1\n",
      "11 conv2d_4\n",
      "12 batch_normalization_4\n",
      "13 activation_4\n",
      "14 conv2d_5\n",
      "15 batch_normalization_5\n",
      "16 activation_5\n",
      "17 max_pooling2d_2\n",
      "18 conv2d_9\n",
      "19 batch_normalization_9\n",
      "20 activation_9\n",
      "21 conv2d_7\n",
      "22 conv2d_10\n",
      "23 batch_normalization_7\n",
      "24 batch_normalization_10\n",
      "25 activation_7\n",
      "26 activation_10\n",
      "27 average_pooling2d_1\n",
      "28 conv2d_6\n",
      "29 conv2d_8\n",
      "30 conv2d_11\n",
      "31 conv2d_12\n",
      "32 batch_normalization_6\n",
      "33 batch_normalization_8\n",
      "34 batch_normalization_11\n",
      "35 batch_normalization_12\n",
      "36 activation_6\n",
      "37 activation_8\n",
      "38 activation_11\n",
      "39 activation_12\n",
      "40 mixed0\n",
      "41 conv2d_16\n",
      "42 batch_normalization_16\n",
      "43 activation_16\n",
      "44 conv2d_14\n",
      "45 conv2d_17\n",
      "46 batch_normalization_14\n",
      "47 batch_normalization_17\n",
      "48 activation_14\n",
      "49 activation_17\n",
      "50 average_pooling2d_2\n",
      "51 conv2d_13\n",
      "52 conv2d_15\n",
      "53 conv2d_18\n",
      "54 conv2d_19\n",
      "55 batch_normalization_13\n",
      "56 batch_normalization_15\n",
      "57 batch_normalization_18\n",
      "58 batch_normalization_19\n",
      "59 activation_13\n",
      "60 activation_15\n",
      "61 activation_18\n",
      "62 activation_19\n",
      "63 mixed1\n",
      "64 conv2d_23\n",
      "65 batch_normalization_23\n",
      "66 activation_23\n",
      "67 conv2d_21\n",
      "68 conv2d_24\n",
      "69 batch_normalization_21\n",
      "70 batch_normalization_24\n",
      "71 activation_21\n",
      "72 activation_24\n",
      "73 average_pooling2d_3\n",
      "74 conv2d_20\n",
      "75 conv2d_22\n",
      "76 conv2d_25\n",
      "77 conv2d_26\n",
      "78 batch_normalization_20\n",
      "79 batch_normalization_22\n",
      "80 batch_normalization_25\n",
      "81 batch_normalization_26\n",
      "82 activation_20\n",
      "83 activation_22\n",
      "84 activation_25\n",
      "85 activation_26\n",
      "86 mixed2\n",
      "87 conv2d_28\n",
      "88 batch_normalization_28\n",
      "89 activation_28\n",
      "90 conv2d_29\n",
      "91 batch_normalization_29\n",
      "92 activation_29\n",
      "93 conv2d_27\n",
      "94 conv2d_30\n",
      "95 batch_normalization_27\n",
      "96 batch_normalization_30\n",
      "97 activation_27\n",
      "98 activation_30\n",
      "99 max_pooling2d_3\n",
      "100 mixed3\n",
      "101 conv2d_35\n",
      "102 batch_normalization_35\n",
      "103 activation_35\n",
      "104 conv2d_36\n",
      "105 batch_normalization_36\n",
      "106 activation_36\n",
      "107 conv2d_32\n",
      "108 conv2d_37\n",
      "109 batch_normalization_32\n",
      "110 batch_normalization_37\n",
      "111 activation_32\n",
      "112 activation_37\n",
      "113 conv2d_33\n",
      "114 conv2d_38\n",
      "115 batch_normalization_33\n",
      "116 batch_normalization_38\n",
      "117 activation_33\n",
      "118 activation_38\n",
      "119 average_pooling2d_4\n",
      "120 conv2d_31\n",
      "121 conv2d_34\n",
      "122 conv2d_39\n",
      "123 conv2d_40\n",
      "124 batch_normalization_31\n",
      "125 batch_normalization_34\n",
      "126 batch_normalization_39\n",
      "127 batch_normalization_40\n",
      "128 activation_31\n",
      "129 activation_34\n",
      "130 activation_39\n",
      "131 activation_40\n",
      "132 mixed4\n",
      "133 conv2d_45\n",
      "134 batch_normalization_45\n",
      "135 activation_45\n",
      "136 conv2d_46\n",
      "137 batch_normalization_46\n",
      "138 activation_46\n",
      "139 conv2d_42\n",
      "140 conv2d_47\n",
      "141 batch_normalization_42\n",
      "142 batch_normalization_47\n",
      "143 activation_42\n",
      "144 activation_47\n",
      "145 conv2d_43\n",
      "146 conv2d_48\n",
      "147 batch_normalization_43\n",
      "148 batch_normalization_48\n",
      "149 activation_43\n",
      "150 activation_48\n",
      "151 average_pooling2d_5\n",
      "152 conv2d_41\n",
      "153 conv2d_44\n",
      "154 conv2d_49\n",
      "155 conv2d_50\n",
      "156 batch_normalization_41\n",
      "157 batch_normalization_44\n",
      "158 batch_normalization_49\n",
      "159 batch_normalization_50\n",
      "160 activation_41\n",
      "161 activation_44\n",
      "162 activation_49\n",
      "163 activation_50\n",
      "164 mixed5\n",
      "165 conv2d_55\n",
      "166 batch_normalization_55\n",
      "167 activation_55\n",
      "168 conv2d_56\n",
      "169 batch_normalization_56\n",
      "170 activation_56\n",
      "171 conv2d_52\n",
      "172 conv2d_57\n",
      "173 batch_normalization_52\n",
      "174 batch_normalization_57\n",
      "175 activation_52\n",
      "176 activation_57\n",
      "177 conv2d_53\n",
      "178 conv2d_58\n",
      "179 batch_normalization_53\n",
      "180 batch_normalization_58\n",
      "181 activation_53\n",
      "182 activation_58\n",
      "183 average_pooling2d_6\n",
      "184 conv2d_51\n",
      "185 conv2d_54\n",
      "186 conv2d_59\n",
      "187 conv2d_60\n",
      "188 batch_normalization_51\n",
      "189 batch_normalization_54\n",
      "190 batch_normalization_59\n",
      "191 batch_normalization_60\n",
      "192 activation_51\n",
      "193 activation_54\n",
      "194 activation_59\n",
      "195 activation_60\n",
      "196 mixed6\n",
      "197 conv2d_65\n",
      "198 batch_normalization_65\n",
      "199 activation_65\n",
      "200 conv2d_66\n",
      "201 batch_normalization_66\n",
      "202 activation_66\n",
      "203 conv2d_62\n",
      "204 conv2d_67\n",
      "205 batch_normalization_62\n",
      "206 batch_normalization_67\n",
      "207 activation_62\n",
      "208 activation_67\n",
      "209 conv2d_63\n",
      "210 conv2d_68\n",
      "211 batch_normalization_63\n",
      "212 batch_normalization_68\n",
      "213 activation_63\n",
      "214 activation_68\n",
      "215 average_pooling2d_7\n",
      "216 conv2d_61\n",
      "217 conv2d_64\n",
      "218 conv2d_69\n",
      "219 conv2d_70\n",
      "220 batch_normalization_61\n",
      "221 batch_normalization_64\n",
      "222 batch_normalization_69\n",
      "223 batch_normalization_70\n",
      "224 activation_61\n",
      "225 activation_64\n",
      "226 activation_69\n",
      "227 activation_70\n",
      "228 mixed7\n",
      "229 conv2d_73\n",
      "230 batch_normalization_73\n",
      "231 activation_73\n",
      "232 conv2d_74\n",
      "233 batch_normalization_74\n",
      "234 activation_74\n",
      "235 conv2d_71\n",
      "236 conv2d_75\n",
      "237 batch_normalization_71\n",
      "238 batch_normalization_75\n",
      "239 activation_71\n",
      "240 activation_75\n",
      "241 conv2d_72\n",
      "242 conv2d_76\n",
      "243 batch_normalization_72\n",
      "244 batch_normalization_76\n",
      "245 activation_72\n",
      "246 activation_76\n",
      "247 max_pooling2d_4\n",
      "248 mixed8\n",
      "249 conv2d_81\n",
      "250 batch_normalization_81\n",
      "251 activation_81\n",
      "252 conv2d_78\n",
      "253 conv2d_82\n",
      "254 batch_normalization_78\n",
      "255 batch_normalization_82\n",
      "256 activation_78\n",
      "257 activation_82\n",
      "258 conv2d_79\n",
      "259 conv2d_80\n",
      "260 conv2d_83\n",
      "261 conv2d_84\n",
      "262 average_pooling2d_8\n",
      "263 conv2d_77\n",
      "264 batch_normalization_79\n",
      "265 batch_normalization_80\n",
      "266 batch_normalization_83\n",
      "267 batch_normalization_84\n",
      "268 conv2d_85\n",
      "269 batch_normalization_77\n",
      "270 activation_79\n",
      "271 activation_80\n",
      "272 activation_83\n",
      "273 activation_84\n",
      "274 batch_normalization_85\n",
      "275 activation_77\n",
      "276 mixed9_0\n",
      "277 concatenate_1\n",
      "278 activation_85\n",
      "279 mixed9\n",
      "280 conv2d_90\n",
      "281 batch_normalization_90\n",
      "282 activation_90\n",
      "283 conv2d_87\n",
      "284 conv2d_91\n",
      "285 batch_normalization_87\n",
      "286 batch_normalization_91\n",
      "287 activation_87\n",
      "288 activation_91\n",
      "289 conv2d_88\n",
      "290 conv2d_89\n",
      "291 conv2d_92\n",
      "292 conv2d_93\n",
      "293 average_pooling2d_9\n",
      "294 conv2d_86\n",
      "295 batch_normalization_88\n",
      "296 batch_normalization_89\n",
      "297 batch_normalization_92\n",
      "298 batch_normalization_93\n",
      "299 conv2d_94\n",
      "300 batch_normalization_86\n",
      "301 activation_88\n",
      "302 activation_89\n",
      "303 activation_92\n",
      "304 activation_93\n",
      "305 batch_normalization_94\n",
      "306 activation_86\n",
      "307 mixed9_1\n",
      "308 concatenate_2\n",
      "309 activation_94\n",
      "310 mixed10\n",
      "Epoch 1/5\n",
      "160/160 [==============================] - 2146s 13s/step - loss: 0.8861 - acc: 0.7379 - val_loss: 15.9582 - val_acc: 0.0046\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 15.95824, saving model to saved_models/inceptionv2.hdf5\n",
      "Epoch 2/5\n",
      "160/160 [==============================] - 2130s 13s/step - loss: 0.7949 - acc: 0.7653 - val_loss: 15.9702 - val_acc: 0.0054\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 15.95824\n",
      "Epoch 3/5\n",
      "160/160 [==============================] - 2130s 13s/step - loss: 0.7474 - acc: 0.7769 - val_loss: 15.9747 - val_acc: 0.0046\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 15.95824\n",
      "Epoch 4/5\n",
      "160/160 [==============================] - 2131s 13s/step - loss: 0.7344 - acc: 0.7840 - val_loss: 15.9759 - val_acc: 0.0046\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 15.95824\n",
      "Epoch 5/5\n",
      "160/160 [==============================] - 2133s 13s/step - loss: 0.7196 - acc: 0.7903 - val_loss: 15.9789 - val_acc: 0.0050\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 15.95824\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xd847285c0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# at this point, the top layers are well trained and we can start fine-tuning\n",
    "# convolutional layers from inception V3. We will freeze the bottom N layers\n",
    "# and train the remaining top layers.\n",
    "\n",
    "# let's visualize layer names and layer indices to see how many layers\n",
    "# we should freeze:\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "    print(i, layer.name)\n",
    "\n",
    "# we chose to train the top 2 inception blocks, i.e. we will freeze\n",
    "# the first 249 layers and unfreeze the rest:\n",
    "for layer in model.layers[:249]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[249:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# we need to recompile the model for these modifications to take effect\n",
    "# we use SGD with a low learning rate\n",
    "from keras.optimizers import SGD\n",
    "inception.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# we train our model again (this time fine-tuning the top 2 inception blocks\n",
    "# alongside the top Dense layers\n",
    "epochs = 5\n",
    "batch_size = 60\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/inceptionv2.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "### Using Image Augmentation\n",
    "inception.fit_generator(datagen.flow(train_tensor, train_target, batch_size=batch_size),\n",
    "                    validation_data=(valid_tensor, valid_target), \n",
    "                    steps_per_epoch=train_tensor.shape[0] // batch_size,\n",
    "                    epochs=epochs, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is surpisingly bad here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XCeption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.xception import Xception\n",
    "from keras.applications.xception import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = preprocess_input(train_tensor)\n",
    "x_valid = preprocess_input(valid_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, None, None, 3 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, None, None, 3 128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, None, None, 3 0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, None, None, 6 18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, None, None, 6 256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, None, None, 6 0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, None, None, 1 8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, None, None, 1 512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, None, None, 1 0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, None, None, 1 17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, None, None, 1 512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, None, None, 1 8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, None, None, 1 0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, None, None, 1 512         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, None, None, 1 0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, None, None, 1 0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, None, None, 2 33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, None, None, 2 1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, None, None, 2 0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, None, None, 2 67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, None, None, 2 1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, None, None, 2 32768       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, None, None, 2 0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, None, None, 2 1024        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, None, None, 2 0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, None, None, 2 0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, None, None, 7 188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, None, None, 7 0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, None, None, 7 186368      add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, None, None, 7 0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, None, None, 7 2912        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, None, None, 7 0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, None, None, 7 0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, None, None, 7 0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, None, None, 7 0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, None, None, 7 0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, None, None, 7 0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, None, None, 7 0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, None, None, 7 0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, None, None, 7 0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, None, None, 7 0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, None, None, 7 0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, None, None, 7 0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, None, None, 7 0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, None, None, 7 0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, None, None, 7 0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, None, None, 7 0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, None, None, 7 0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, None, None, 7 0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, None, None, 7 0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, None, None, 7 0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, None, None, 7 0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, None, None, 7 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, None, None, 7 536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, None, None, 7 0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, None, None, 7 536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, None, None, 7 2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, None, None, 7 0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, None, None, 7 536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, None, None, 7 2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, None, None, 7 0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, None, None, 7 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, None, None, 7 536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, None, None, 7 0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, None, None, 7 536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, None, None, 7 2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, None, None, 7 0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, None, None, 7 536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, None, None, 7 2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, None, None, 7 0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, None, None, 7 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, None, None, 7 536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, None, None, 7 0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, None, None, 7 536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, None, None, 7 2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, None, None, 7 0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, None, None, 7 536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, None, None, 7 2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, None, None, 7 0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, None, None, 7 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, None, None, 7 536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, None, None, 7 0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, None, None, 1 752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, None, None, 1 4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, None, None, 1 745472      add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, None, None, 1 0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, None, None, 1 4096        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, None, None, 1 0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, None, None, 1 1582080     add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, None, None, 1 6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, None, None, 1 0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, None, None, 2 3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, None, None, 2 8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, None, None, 2 0           block14_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           block14_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 1000)         2049000     avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 22,910,480\n",
      "Trainable params: 22,855,952\n",
      "Non-trainable params: 54,528\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = Xception(weights='imagenet')\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_xception = Model(inputs=base_model.input, outputs=base_model.get_layer('avg_pool').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 4809s 501ms/step\n",
      "2400/2400 [==============================] - 1176s 490ms/step\n"
     ]
    }
   ],
   "source": [
    "xception_train_features = model_xception.predict(x_train, verbose = 1)\n",
    "xception_valid_features = model_xception.predict(x_valid, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('xception_features.pickle', 'rb') as f:\n",
    "    xception_train_features, xception_valid_features, xception_test_features = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=10, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = decomposition.PCA(n_components = 10)\n",
    "pca.fit(xception_valid_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04240138 0.03748818 0.03666271 0.03355619 0.03155714 0.02659563\n",
      " 0.02296594 0.02123191 0.01972728 0.01899961]\n",
      "[0.04240138 0.07988957 0.11655228 0.15010846 0.1816656  0.20826124\n",
      " 0.23122717 0.25245908 0.27218637 0.29118598]\n"
     ]
    }
   ],
   "source": [
    "# pca.explained_variance_ratio_ nous donne le pourcentage de variance explique \n",
    "\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(pca.explained_variance_ratio_.cumsum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(valid_target[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2400, 10)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_projected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pylab as pl\n",
    "pl.figure(figsize=(10, 10))\n",
    "j=1\n",
    "for i in range(0, X_projected.shape[0]):\n",
    "    if valid_target[i] == 0:\n",
    "        c1 = pl.scatter(X_projected[i,0], X_projected[i,j], c='r', marker='+')\n",
    "    elif valid_target[i] == 1:\n",
    "        c2 = pl.scatter(X_projected[i,0], X_projected[i,j], c='g', marker='o')\n",
    "    elif valid_target[i] == 2:\n",
    "        c3 = pl.scatter(X_projected[i,0], X_projected[i,j], c='b', marker='*')\n",
    "    elif valid_target[i] == 3:\n",
    "        c4 = pl.scatter(X_projected[i,0], X_projected[i,j], c='y', marker='v')\n",
    "    elif valid_target[i] == 4:\n",
    "        c5 = pl.scatter(X_projected[i,0], X_projected[i,j], c='c', marker='X')\n",
    "pl.legend([c1, c2, c3, c4, c5], ['Chihuahua', 'Japanese_spaniel', 'Maltese_dog', 'Pekinese', 'Shih-Tsu'])\n",
    "pl.title('PCA with 2 compononents of the first 5 dog breeds')\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sn\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-SNE done! Time elapsed: 435.3764672279358 seconds\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "model = TSNE(n_components=2, random_state=0, perplexity=50, n_iter=5000)\n",
    "tsne_data = model.fit_transform(xception_valid_features)\n",
    "print('t-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pl.figure(figsize=(10, 10))\n",
    "j=1\n",
    "for i in range(0, tsne_data.shape[0]):\n",
    "    if valid_target[i] == 100:\n",
    "        c1 = pl.scatter(tsne_data[i,0], tsne_data[i,j], c='r', marker='+')\n",
    "    elif valid_target[i] == 99:\n",
    "        c2 = pl.scatter(tsne_data[i,0], tsne_data[i,j], c='g', marker='o')\n",
    "    elif valid_target[i] == 98:\n",
    "        c3 = pl.scatter(tsne_data[i,0], tsne_data[i,j], c='b', marker='*')\n",
    "    elif valid_target[i] == 97:\n",
    "        c4 = pl.scatter(tsne_data[i,0], tsne_data[i,j], c='y', marker='v')\n",
    "    elif valid_target[i] == 96:\n",
    "        c5 = pl.scatter(tsne_data[i,0], tsne_data[i,j], c='c', marker='X')\n",
    "pl.legend([c1, c2, c3, c4, c5], ['African_hunting_dog', 'Dhole', 'Dingo', 'Mexican_hairless', 'Standard_poodle'])\n",
    "pl.title('Visualization of the 5 last breeds with TSNE')\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Training  DummyClassifier(constant=None, random_state=None, strategy='stratified')\n",
      "Accuracy on test set =  0.75\n",
      "================================================================================\n",
      "Training  SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False)\n",
      "Accuracy on test set =  71.75\n",
      "================================================================================\n",
      "Training  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Accuracy on test set =  78.83333333333333\n",
      "================================================================================\n",
      "Training  MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "Accuracy on test set =  77.75\n",
      "================================================================================\n",
      "Training  Perceptron(alpha=0.0001, class_weight=None, eta0=1.0, fit_intercept=True,\n",
      "      max_iter=None, n_iter=None, n_jobs=1, penalty=None, random_state=0,\n",
      "      shuffle=True, tol=None, verbose=0, warm_start=False)\n",
      "Accuracy on test set =  69.79166666666666\n",
      "================================================================================\n",
      "Training  PassiveAggressiveClassifier(C=1.0, average=False, class_weight=None,\n",
      "              fit_intercept=True, loss='hinge', max_iter=None, n_iter=None,\n",
      "              n_jobs=1, random_state=None, shuffle=True, tol=None,\n",
      "              verbose=0, warm_start=False)\n",
      "Accuracy on test set =  75.375\n",
      "================================================================================\n",
      "Training  RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "Accuracy on test set =  62.958333333333336\n",
      "================================================================================\n",
      "Training  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False)\n",
      "Accuracy on test set =  77.66666666666666\n"
     ]
    }
   ],
   "source": [
    "for classifier in [dummy, sgd, lr, mn, perceptron, pac, rfc, mlpc]:\n",
    "    train_and_test_model(classifier, xception_train_features, train_target, xception_valid_features, valid_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final 2 models : logistic regression vs SVC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_estimator = lr.fit(xception_train_features, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test = preprocess_input(test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8580/8580 [==============================] - 4351s 507ms/step\n"
     ]
    }
   ],
   "source": [
    "xception_test_features = model_xception.predict(x_test, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('xception_features.pickle', 'wb') as f:\n",
    "    pickle.dump([xception_train_features, xception_valid_features, xception_test_features], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set =  99.97916666666666\n",
      "Accuracy on validation set =  78.83333333333333\n",
      "Accuracy on test set =  85.22144522144522\n"
     ]
    }
   ],
   "source": [
    "pred_train = best_estimator.predict(xception_train_features)\n",
    "score_train_accuracy = metrics.accuracy_score(train_target, pred_train)\n",
    "\n",
    "print('Accuracy on training set = ', score_train_accuracy*100)\n",
    "\n",
    "pred_valid = best_estimator.predict(xception_valid_features)\n",
    "score_valid_accuracy = metrics.accuracy_score(valid_target, pred_valid)\n",
    "\n",
    "print('Accuracy on validation set = ', score_valid_accuracy*100)\n",
    "\n",
    "pred_test = best_estimator.predict(xception_test_features)\n",
    "score_test_accuracy = metrics.accuracy_score(test_target, pred_test)\n",
    "\n",
    "print('Accuracy on test set = ', score_test_accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]Accuracy on training set =  81.02083333333333\n",
      "Accuracy on validation set =  78.5\n",
      "Accuracy on test set =  87.22610722610723\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(verbose = 10).fit(xception_train_features, train_target)\n",
    "pred_train = svc.predict(xception_train_features)\n",
    "score_train_accuracy = metrics.accuracy_score(train_target, pred_train)\n",
    "\n",
    "print('Accuracy on training set = ', score_train_accuracy*100)\n",
    "\n",
    "pred_valid = svc.predict(xception_valid_features)\n",
    "score_valid_accuracy = metrics.accuracy_score(valid_target, pred_valid)\n",
    "\n",
    "print('Accuracy on validation set = ', score_valid_accuracy*100)\n",
    "\n",
    "pred_test = svc.predict(xception_test_features)\n",
    "score_test_accuracy = metrics.accuracy_score(test_target, pred_test)\n",
    "\n",
    "print('Accuracy on test set = ', score_test_accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('modele_final.pickle', 'wb') as g:\n",
    "    pickle.dump([model_xception, svc], g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "confusion matrix\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # confusion matrix\n",
    "print('\\nconfusion matrix')\n",
    "conf = confusion_matrix(test_target, pred_test)\n",
    "f = plt.figure(figsize=(20,20))\n",
    "ax = f.add_subplot(1,1,1)\n",
    "img = ax.imshow(conf, cmap=plt.cm.jet, interpolation='nearest')\n",
    "ax.set_xlabel('predicted')\n",
    "ax.set_ylabel('true')\n",
    "\n",
    "plt.colorbar(img, ax=ax)\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
